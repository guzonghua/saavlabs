{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guzonghua/saavlabs/blob/main/Lab1_Adversarial_Attacks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1.** This blog article and source code describes how to train a model for Traffic Sign Recognition through fine-tuning a pretrained MobileNetV3 Large model\n",
        "\n",
        "Traffic Sign Recognition using PyTorch and Deep Learning\n",
        "\n",
        "https://debuggercafe.com/traffic-sign-recognition-using-pytorch-and-deep-learning/\n",
        "\n",
        "Please follow his steps to train a model for Traffic Sign Recognition. \n",
        "\n",
        "Optional: To save training time, you may use the MobileNetV3 Small model instead of MobileNetV3 Large:\n",
        "https://pytorch.org/vision/main/models/generated/torchvision.models.mobilenet_v3_small.html\n",
        "\n",
        "By having this line in model.py: \n",
        "\n",
        "    model = models.mobilenet_v3_large(pretrained=pretrained)\n",
        "    ...\n",
        "    # Change the final classification head.\n",
        "    model.classifier[3] = nn.Linear(in_features=1280, out_features=num_classes)\n",
        "\n",
        "**Step 2.** Follow the steps in \"Chapter 3 - Adversarial examples, solving the inner maximization\" in the tutorial \"Adversarial Robustness - Theory and Practice\" 2018 to create attack images:\n",
        "\n",
        "https://adversarial-ml-tutorial.org/adversarial_examples/\n",
        "\n",
        "Use your trained CNN, perform the following steps: \n",
        "\n",
        "2.1 Untargeted attack using Fast Gradient Sign Method (FGSM), using the function fgsm().\n",
        "\n",
        "2.2 Untargeted attack using Projected Gradient Descent, using the function pgd_linf() (use the Projected Steepest Descent variant to accelerate the process).\n",
        "\n",
        "2.3 Targeted attack using Projected Gradient Descent, using the function pgd_linf_targ(), which aims to maximize logit of the target class y_targ and minimize logit of the true class y. You may choose any target class, but I suggest using \"Speed Limit\".\n",
        "\n",
        "2.4 Targeted attack using Projected Gradient Descent, using the function pgd_linf_targ2(),  which  aims to maximize logit of the target class y_targ and minimize logit of all the other classes y'.\n",
        "For each attack, report the accuracy of the attacked classifier on the testset, and show visualization of a few examples of successful attack (original image and attacked image). \n",
        "\n",
        "**Submission instructions**: You may use either Google CoLab or your local machine. If you use CoLab, please send your CoLab web link. Otherwise, please submit an ipynb or Python file, along with a short report in PDF containing the test accuracy and visualization of examples, as well as any problems you encountered or any insights you want to share. You may write the report with WORD, or choose to embed the report within the ipynb file, execute it to show all results, then and print it as PDF. "
      ],
      "metadata": {
        "id": "d6Mjv7Y0QxhR"
      }
    }
  ]
}